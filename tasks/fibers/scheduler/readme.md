# Scalable Scheduler

## Пререквизиты

- [fibers/mutex](/tasks/fibers/mutex)
- [futures/executors](/tasks/futures/executors)
- [lockfree/steal](/tasks/lockfree/steal)

----

В этой задаче вы должны реализовать [масштабируемый планировщик](exe/executors/tp/fast) для файберов.

Масштабируемость означает, что с ростом числа ядер планировщик должен выполнять пропорционально больше задач в единицу времени.

## Планировщик для файберов

До этого момента в качестве планировщика файберов мы использовали простой пул потоков с разделяемой очередью задач.

Пул потоков подходит для вычислительно тяжелых и независимых задач. Но в случае файберов задачи не являются ни тяжелыми, ни независимыми.

### Быстрые задачи и contention на очереди

Задачи для файберов получаются очень короткими, так что накладные расходы на планирование этих задач становятся сопоставимы с их исполнением.

При этом процедура планирования задачи упирается в общую очередь, т.е. в общий мьютекс, который и ограничивает масштабируемость: число критических секций в единицу времени для мьютекса с ростом числа ядер не просто не растет, а даже уменьшается.

### Коммуникация, локальность, кэши

Кроме того, файберы могут интенсивно коммуницировать между собой через примитивы синхронизации (мьютексы и каналы), 
явно (в случае каналов) или неявно (в случае мьютексов) передавая друг другу сообщения.

Если такие зависимые задачи запускать на одном ядре и последовательно, то можно получить выигрыш за счет того, что получатель 
"сообщения" прочтет его прямо из кэша процессора, ему не потребуется идти за ним в оперативную память.

## Дизайн

Центральная идея – _шардирование_.

### Шардирование

У каждого потока-воркера есть собственная ограниченная очередь задач (будем называть эту очередь _локальной_), воркер работает в первую очередь с ней. 

Локальные очереди позволяют воркерам
- Избегать координации друг с другом, что повышает пропускную способность планировщика.
- Кластеризовать коммуницирующие задачи (например, файберы) на одном ядре, что повышает эффективность кэшей.

С другой стороны, шардирование усложняет: 
1) Балансировку нагрузки между воркерами, так как задачи могут распределиться и генерироваться на воркерах неравномерно. 
2) Парковку воркеров, так как больше нельзя атомарно проверить пустоту общей очереди и запарковать поток на кондваре.

### Балансировка нагрузки

Воркеры разделяют общую очередь задач неограниченной емкости (будем называть ее _глобальной_): в нее они выгружают излишки своих задач, из нее они забирают новые задачи, когда локальная очередь опустошается.

Когда и локальная, и глобальная очереди оказываются пусты, воркеры воруют задачи прямо из локальных очередей других воркеров ([Work stealing](https://en.wikipedia.org/wiki/Work_stealing)).

### LIFO

Для более эффективного исполнения коммуницирующих задач к локальной очереди на каждом воркере добавляется LIFO-слот, который имеет наивысший приоритет при выборе очередной задачи для исполнения.

### Алгоритм

#### Планирование задачи

- Если задача планируется из воркера пула, то она добавляется в хвост локальной очереди либо в LIFO-слот, если пользователь явно попросил о последнем с помощью специальной подсказки.

- Если задача планируется из внешнего (по отношению к пулу) потока, то она добавляется в хвост общей очереди.

#### Выбор задачи для запуска

Воркер перебирает следующие источники задач (в порядке убывания приоритета):

1) LIFO-слот
2) Локальная очередь
3) Глобальная очередь
4) Work stealing 

#### Semi-Fairness

Каждая запланированная в пул потоков задача должна быть исполнена.

Однако если задачу выбирать в соответствии с планом выше, то возможны сценарии, когда задача находится в планировщике, но воркеры ее не запускают:

1) Задача находится в глобальной очереди, при этом в локальных очередях воркеров всегда остаются задачи, так что воркеры не проверяют глобальную очередь.

2) Два файбера обмениваются сообщениями через каналы, по циклу запуская друг друга через LIFO-слот, так что воркер вообще не проверяет локальную очередь.

Для решения первой проблемы периодически опрашивайте глобальную очередь задач _до_ проверки LIFO-слота (вспомните фундаментальную константу Дмитрия Вьюкова – 61).

Для решения второй проблемы ограничивайте число последовательных запусков задач через LIFO-слот. Можно думать об этом так: задача, взятая из LIFO-слота, наследует квант планирования предшествующей задачи.

#### Парковка

Воркер, который не смог найти задачи для исполнения, должен парковаться и не тратить процессорное время.

Но делать это нужно аккуратно: воркер не должен парковаться, если где-то в очередях планировщика остаются еще не запущенные задачи.

## Реализация

### Интрузивность

Для реализации планировщика потребуются _интрузивные_ задачи.

Под интрузивной мы понимаем задачу, которая сама управляет временем своей жизни и которая умеет встраиваться во внутренние структуры данных планировщика.

Интрузивная задача реализует интерфейс [`ITask`](exe/executors/task.hpp) с двумя методами:
- `Run` – выполнить задачу
- `Discard` – задача выброшена экзекутором (вспомним метод `Stop` у `ThreadPool`)

Интрузивная задача наследуется от `TaskBase`, в который дополнительно помещается указатель
для связывания задач в очереди.

### Локальная очередь

[`WorkStealingQueue`](exe/executors/tp/fast/queues/work_stealing_queue.hpp)

Локальная очередь задач представляет собой лок-фри циклический буфер фиксированного размера.

- Методы `TryPush` и `TryPop` вызывает только владеющий очередью воркер.
- Метод `Grab` зовется
  - другими воркерами при воровстве задач,
  - самим воркером для выгрузки задач в общую очередь при переполнении локальной.

### Глобальная очередь

[`GlobalQueue`](exe/executors/tp/fast/queues/global_queue.hpp)

Глобальная очередь служит для балансировки нагрузки между воркерами.

#### Offload

Если локальная очередь воркера переполняется в результате планирования новой задачи, то
половина задач из нее выгружается в глобальную очередь с помощью метода `OffloadTasksToGlobalQueue`.

Минимизируйте работу в критической секции при выгрузке задач в глобальную очередь: используйте в `GlobalQueue` [интрузивный список](https://gitlab.com/Lipovsky/wheels/-/blob/master/wheels/intrusive/forward_list.hpp),
добавляйте в него пачку задач за O(1) с помощью метода `Append`.

#### Grab

Если локальная очередь воркера оказывается пуста, воркер пытается забрать пачку задач из глобальной очереди с помощью `GrabTasksFromGlobalQueue`.

В качестве размера пачки можно взять текущий размер глобальной очереди, поделенный на число воркеров.

### Work stealing

Если локальная и глобальная очередь пусты, то воруйте задачи напрямую из локальных очередей других воркеров.

Ограничивайте число одновременно ворующих воркеров 1/2 от их общего числа.

Рандомизируйте порядок обхода "жертв" с помощью [`mt19937_64`](https://en.cppreference.com/w/cpp/numeric/random).

Для инициализации вихря Мерсенна в воркере используйте [`random_device` из `twist`](https://gitlab.com/Lipovsky/twist/-/blob/master/twist/stdlike/random.hpp): он обеспечит детерминизм исполнения при запуске тестов под файберами.

### LIFO-слот и честность

Поддержите LIFO-слот при планировании: задача, запланированная прямо из пула потоков, попадает в этот слот и запускается уже на следующей итерации воркера.

Если при планировании задачи в LIFO-слот оказывается, что тот уже занят другой задачей, то последняя вытесняется в хвост локальной очереди.

Ограничьте число последовательных итераций планирования через LIFO-слот для обеспечения честности.

#### Подсказки

Дайте пользователю (например, файберам) возможность управлять планированием: поддержите в методе `Execute` (и в `FiberHandle::Schedule`) дополнительный параметр `Hint` – подсказку планировщику.

Подсказки недирективны: корректность кода, который дает подсказку планировщику, не должна зависеть от того, была ли эта подсказка учтена при планировании.

#### Default

По умолчанию `fast::ThreadPool` должен использовать FIFO-планирование. 

Пользователь, который ставит в приоритет производительность, должен переходить на LIFO-планирование явно, указывая `Hint::Next`.

### `Yield`

По умолчанию задачи, которые планируются из самого планировщика, обслуживаются текущим потоком-воркером: попадают либо в его локальную очередь, либо в LIFO-слот.

Для функции `Yield` такое поведение не подходит: файбер хочет уступить исполнение всем файберам, а не только файберам из локальной очереди.

Сделайте для `Yield` отдельную подсказку и отправляйте файбер в конец глобальной очереди.

### Координация / парковка воркеров

Воркеры стараются работать независимо, но иногда им необходима координация, например, для парковки.

Изучите [механизм парковки потоков](https://github.com/golang/go/blob/d2552037426fe5a190c74172562d897d921fe311/src/runtime/proc.go#L31) в планировщике `Go`.

Изучите [реализацию](https://github.com/tokio-rs/tokio/blob/master/tokio/src/runtime/scheduler/multi_thread/idle.rs) этого механизма в планировщике [Tokio](https://github.com/tokio-rs/tokio).

Используйте аналогичную двухфазную парковку, реализуйте ее через класс [`Coordinator`](exe/executors/tp/fast/coordinator.hpp). 

Проверка очередей на пустоту после анонса парковки – метод `TryPickTaskBeforePark`.

Непосредственно для парковки воркера используйте отдельный атомик `wakeups`.

### Аллокации

Планировщик не должен аллоцировать динамическую память при планировании / исполнении задач:
- Локальная очередь – фиксированный буфер указателей на задачи
- Глобальная очередь – интрузивный контейнер для задач

### Метрики

Собирайте [метрики](exe/executors/tp/fast/metrics.hpp), например:

- Сколько задач было запущено через LIFO-слот / локальную очередь / глобальную очередь
- Сколько раз воркеры воровали задачи, выгружали задачи в глобальную очередь, забирали задачи из глобальной очереди 
- Сколько раз воркеры парковались из-за отсутствия задач
- и т.п.

Метрики помогут понять поведение вашей реализации в разных сценариях нагрузки.

Собирайте метрики для каждого воркера независимо, без синхронизации.

### Конфиг

Поддержите конфиг для свободных параметров, которые возникают в реализации: так будет удобнее исследовать влияние этих параметров на поведение пула.

## Профилирование

Профилируйте вашу реализацию на [`workloads`](workloads/main.cpp) чтобы понять, на что вы расходуете время при планировании.

[Flame Graphs](https://www.brendangregg.com/flamegraphs.html)

## Задание

### Подготовительные шаги

1) Реализуйте интрузивные задачи в [futures/executors](/tasks/futures/executors), без них хороший планировщик написать не получится.
2) Перенесите пул потоков из [futures/executors](/tasks/futures/executors), он послужит baseline-ом для нового планировщика.
3) Перенесите файберы из [fibers/mutex](/tasks/fibers/mutex), адаптируйте их для запуска в произвольном экзекуторе.

### Планировщик

4) Реализуйте шардированный планировщик с локальными очередями и общей очередью для балансировки нагрузки.
5) Реализуйте work stealing.
6) Поддержите подсказки для экзекуторов и LIFO-планирование через выделенный слот.
7) [Бонусный уровень] Реализуйте блокировку потоков планировщика с помощью координатора.

## References

### Work Stealing

- [Scheduling Multithreaded Computations by Work Stealing](http://supertech.csail.mit.edu/papers/steal.pdf)
- https://en.wikipedia.org/wiki/Work_stealing

### Дизайн

- [Scalable Go Scheduler Design Doc](https://golang.org/s/go11sched)
- [Go scheduler: Implementing language with lightweight concurrency](https://www.youtube.com/watch?v=-K11rY57K7k)
- [Making the Tokio scheduler 10x faster](https://tokio.rs/blog/2019-10-scheduler)

### Реализации

- [Golang](https://github.com/golang/go/blob/master/src/runtime/proc.go)
- [Tokio (Rust)](https://github.com/tokio-rs/tokio/tree/master/tokio/src/runtime/thread_pool)
- [Kotlin Coroutines](https://github.com/Kotlin/kotlinx.coroutines/blob/master/kotlinx-coroutines-core/jvm/src/scheduling/CoroutineScheduler.kt)
